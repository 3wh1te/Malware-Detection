# coding=utf-8
import networkx
import os
import collections
import pandas as pd
import tqdm
"""
分析label的分布，分布越平均说明这个函数鉴别能力越差，分布越不均说明该函数有一定的鉴别能力，每个函数存在的label数量
每个类别平均的指令长度 Done
每个类别平均点的个数，边的个数 Done
每个类别内部点和外部点平均占比 Done
"""

# gml_path = '../gmls/'
# labels = pd.read_csv('data/trainLabels.csv')
# labels.set_index('Id', inplace=True)
# result1 = []
# result2 = []
# for gml_file in tqdm.tqdm(os.listdir(gml_path)):
#     class_f = labels.loc[gml_file.split('.')[0], 'Class']
#     G = networkx.read_gml(gml_path + gml_file, label='id')
#     node_num = len(G.nodes)
#     edge_num = len(G.edges)
#     result2.append((class_f, node_num, edge_num))
#     for node in G.nodes:
#         node = G.nodes[node]
#         label = node['label']
#         t = node['type']
#         if t == 'Internal':
#             feature = len(node['features']['val'])
#         else:
#             feature = 0
#         result1.append((class_f, label, t, feature))
# df1 = pd.DataFrame(result1, columns=['label', 'fun_id', 'type', 'inst_len'])
# df1.to_csv('data/data_analysis/re.csv')
# df2 = pd.DataFrame(result2, columns=['label', 'node num', 'edge num'])
# df2.to_csv('data/data_analysis/re2.csv')

# 点边个数
# data = pd.read_csv('data/data_analysis/re3.csv')
# data.set_index('index', inplace=True)
# print(data.info())
# gdata = data.groupby(['label'])
# print(gdata.count())
# # gdata.count().to_csv('data/data_analysis/g_num.csv')
# mean = gdata.mean().add_prefix('mean_')
# print(mean)
# mean.to_csv('data/data_analysis/node_edge.csv')

# 平均指令长度图以及内部外部占比

# data = pd.read_csv('data/data_analysis/re.csv')
# data.set_index('label', inplace=True)
# print(data.info())
# gdata = data.groupby(['label'])
#
# inst_len = gdata.mean().add_prefix('mean_')
# # 平均长度
# print(inst_len)
# inst_len.to_csv('data/data_analysis/inst_len.csv')
# # 点的个数
# print(gdata.count())
#
# gdata = data.groupby(['label', 'type'])
# print(gdata.count())

# gdata.count().to_csv('data/data_analysis/internalExternal.csv')
# label分布
data = pd.read_csv('data/data_analysis/re.csv')
print(data.head())
gdata = data.groupby('fun_id')
# print(gdata.groups)
print(len(gdata))

d = []
for n, g in tqdm.tqdm(gdata['label']):

    g = pd.Categorical(g)
    g = g.tolist()
    if len(g) > 10:
        d.append(len(set(g)))
    # print(len(set(g)))
    # print(len(g.groupby('label')))
print(len(d))
d = collections.Counter(d).most_common()
print(d)
data = pd.DataFrame(list(d), columns=['class_num', 'times'])
data.set_index('class_num', inplace=True)
data.to_csv('data/data_analysis/distri_30000.csv')