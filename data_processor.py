# coding=utf-8
from tensorflow.keras.preprocessing.text import Tokenizer
import os.path as osp
from torch_geometric.io import read_tu_data
import os
import json
import numpy as np
import torch
from torch_geometric.data import InMemoryDataset
import pandas as pd
from graphviz import Digraph
'''
todo: 如何将一个描述图的gdl转化成邻接矩阵A、度矩阵D、特征矩阵X？
todo: 不同的图的点的个数是不同的，那么矩阵的shape如何确定，也就是n的值是多少？不需要统一
'''


class MyDataset(InMemoryDataset):
    def __init__(self, root, name, transform=None, pre_transform=None,
                 pre_filter=None, use_node_attr=False, use_edge_attr=False,
                 cleaned=False):
        self.name = name
        self.cleaned = cleaned
        super(MyDataset, self).__init__(root, transform, pre_transform,
                                        pre_filter)
        self.data, self.slices = torch.load(self.processed_paths[0])
        if self.data.x is not None and not use_node_attr:
            num_node_attributes = self.num_node_attributes
            self.data.x = self.data.x[:, num_node_attributes:]
        if self.data.edge_attr is not None and not use_edge_attr:
            num_edge_attributes = self.num_edge_attributes
            self.data.edge_attr = self.data.edge_attr[:, num_edge_attributes:]

    @property
    def raw_dir(self):
        name = 'raw{}'.format('_cleaned' if self.cleaned else '')
        return osp.join(self.root, self.name, name)

    @property
    def processed_dir(self):
        name = 'processed{}'.format('_cleaned' if self.cleaned else '')
        return osp.join(self.root, self.name, name)

    @property
    def num_node_labels(self):
        if self.data.x is None:
            return 0
        for i in range(self.data.x.size(1)):
            x = self.data.x[:, i:]
            if ((x == 0) | (x == 1)).all() and (x.sum(dim=1) == 1).all():
                return self.data.x.size(1) - i
        return 0

    @property
    def num_node_attributes(self):
        if self.data.x is None:
            return 0
        return self.data.x.size(1) - self.num_node_labels

    @property
    def num_edge_labels(self):
        if self.data.edge_attr is None:
            return 0
        for i in range(self.data.edge_attr.size(1)):
            if self.data.edge_attr[:, i:].sum() == self.data.edge_attr.size(0):
                return self.data.edge_attr.size(1) - i
        return 0

    @property
    def num_edge_attributes(self):
        if self.data.edge_attr is None:
            return 0
        return self.data.edge_attr.size(1) - self.num_edge_labels

    @property
    def raw_file_names(self):
        names = ['A', 'graph_indicator']
        return ['{}_{}.txt'.format(self.name, name) for name in names]

    @property
    def processed_file_names(self):
        return 'data.pt'

    def download(self):
        pass

    def process(self):
        self.data, self.slices = read_tu_data(self.raw_dir, self.name)

        if self.pre_filter is not None:
            data_list = [self.get(idx) for idx in range(len(self))]
            data_list = [data for data in data_list if self.pre_filter(data)]
            self.data, self.slices = self.collate(data_list)

        if self.pre_transform is not None:
            data_list = [self.get(idx) for idx in range(len(self))]
            data_list = [self.pre_transform(data) for data in data_list]
            self.data, self.slices = self.collate(data_list)

        torch.save((self.data, self.slices), self.processed_paths[0])

    def __repr__(self):
        return '{}({})'.format(self.name, len(self))


# 提取节点特征矩阵、标签、邻接矩阵
class Processor:
    def __init__(self, path, type):
        '''
        :param path: 文件路径
        :param type: 文件类型
        '''
        self.path = path
        self.type = type
        self.edge_index = []
        self.X = []
        self.Y = []
        self.process()
        # self.fdict = self.generate_dict()
        self.labels = pd.readcsv('data/trainLabels.csv')

    def process(self):
        gdls = os.listdir(self.path)
        for gdl in gdls:
            A, node_attr = self.process_one('{0}/{1}'.format(self.path, gdl))
            self.X.append(node_attr)
            self.edge_index.append(A)
            self.Y.append(self.labels[gdl.split('.')[0]])

    def process_one(self, gdl_file):
        A = []
        node_attr = []
        with open(gdl_file, 'r') as gdl:
            data = gdl.readlines()
        for line in data:
            if line.startswith('node'):
                node = line.split('node:')[1].split(' ')
                node_attr.append(eval(node[5]))
            if line.startswith('edge'):
                edge = line.split('edge:')[1].split(' ')
                A.append((eval(edge[3]), eval(edge[5])))
        return A, node_attr

    def get_data(self):
        return self.edge_index, self.X, self.Y

    #  将数据存入文件当中
    def save_data(self):
        indicator = [1]
        with open('data/gdl/raw/gdl_graph_indicator.txt', 'w') as wgif:
            for index, g in enumerate(self.X):
                indicator.append(len(g))
                for _ in range(len(g)):
                    wgif.write('{}\n'.format(str(index + 1)))
        indicator = np.cumsum(np.array(indicator))

        with open('data/gdl/raw/gdl_A.txt', 'w') as waf:
            for index, g in enumerate(self.edge_index):
                start = indicator[index]
                for edge in g:
                    source = int(edge[0])
                    target = int(edge[1])
                    waf.write('\t{0},{1}\n'.format(str(start + source), str(start + target)))
                    waf.write('\t{0},{1}\n'.format(str(start + target), str(start + source)))

        with open('data/processed/gdl_attr.txt', 'w') as watf:
            for g in self.X:
                for node in g:
                    watf.write(node + '\n')

        with open('data/gdl/raw/gdl_graph_labels.txt', 'w') as wlbf:
            for y in self.Y:
                wlbf.write(y + '\n')

    # app name
    def get_title(self, gdl):
        with open(gdl, 'r') as rf:
            return rf.readlines()[1]

    # 加载节点字典
    def load_dict(self, path):
        with open(path, 'r') as fp:
            self.fdict = json.load(fp)

    # 生成字典
    def generate_dict(self):
        tokenizer = Tokenizer(split=' ')
        seq = [' '.join(x) for x in self.X]
        tokenizer.fit_on_texts(seq)
        return tokenizer.to_json()

    # 将字典保存到本地
    def save_dict(self, path):
        with open(path, 'w') as fp:
            json.dump(self.fdict, fp)

def generate_cfg(path):
    with open(path, 'r', encoding='ISO-8859-1') as fd:
        lines = [l.strip('\n') for l in fd.readlines()]

    # 遍历label，找到label对应的addr（应该是第一个label的addr）
    label_addrs = dict()

    for i in range(len(lines)):
        a = lines[i]
        if a[0] == '(' and a[-1] == ')':
            j = i - 1
            while True:
                if lines[j][0] == '(' and lines[j][-1] == ')':
                    j -= 1
                    continue
                label_addrs[a.strip("()")] = j + 1
                break

    # 按顺序遍历汇编，以 branch 语句作为BB的结束，以 branch 语句的目的地作为BB的开始
    # sps存放各个BB的开头地址
    sps = set()
    sps.add(0)
    sps.add(len(lines))
    for i in range(len(lines) - 1):
        a, b = lines[i], lines[i + 1]
        if "jmp" in b or "jlt" in b or "jeq" in b or "jgt" in b or "jle" in b or "jne" in b or "jge" in b or 'jz' in b:
            if "@" in a:
                # 找到label对应的addr
                print("Branch at", b, "to", a, label_addrs.get(a.strip('@'), 0))
                # 检查是不是最后一个指令
                if i + 2 < len(lines):
                    sps.add(i + 2)
                sps.add(label_addrs.get(a.strip('@'), 0))
            else:
                print("Indirect Branch:", a, b)
    sps = list(sps)
    sps.sort()
    print(sps)

    bbs = []
    for i in range(len(sps) - 1):
        a, b = sps[i], sps[i + 1]
        bbs.append((a, b))


    # 使用API，按地址从小到大顺序创建各个BB
    dot = Digraph(comment='The Round Table')
    for start, end in bbs:
        dot.node('Node%d' % start, 'Some data %d~%d' % (start, end), shape='box')

    # 创建连接关系：如果末尾是普通语句，就连接到下一个，如果末尾是跳转语句，就连接到跳转的位置
    for start, end in bbs:
        bb = lines[start:end]
        a, b = bb[-2], bb[-1]
        if "JMP" in b and '@' in a:
            nextBB = label_addrs[a.strip('@')]
            dot.edge('Node%d' % start, 'Node%d' % nextBB)
        elif ("JLT" in b or "JEQ" in b or "JGT" in b or "JLE" in b or "JNE" in b or "JGE" in b) and '@' in a:
            nextBB = label_addrs[a.strip('@')]
            dot.edge('Node%d' % start, 'Node%d' % nextBB)
            dot.edge('Node%d' % start, 'Node%d' % end)
        else:
            dot.edge('Node%d' % start, 'Node%d' % end)
    print(dot.source)
    dot.view(directory='data/CFGs/')  # 后面这句就注释了，也可以使用这个命令查看效果

if __name__ == '__main__':
    # p = Processor('data/gdl_samples', 'gdl')
    # p.save_dict('data/dict/dict.json')
    # p.save_data()
    generate_cfg('data/sample/0A32eTdBKayjCWhZqDOQ.asm')
    # a, x = p.process_one('data/gdl_samples/test.gdl')
    # print(p.edge_index)
    # print(p.X)
    # print(p.Y)
    # p.save_data()
